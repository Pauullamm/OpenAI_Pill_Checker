{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNpLd9DhJosSfxeYzfWTE7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pauullamm/OpenAI_Pill_Checker/blob/main/OpenAI_Pill_Checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description: Python scripts to prepare a text-based AI model fine-tuned on an OpenAI davinci-002 model\n",
        "\n",
        "Have you ever wanted a pill identifer tool to check the name of a tablet/capsule by its description?\n",
        "\n",
        "This Jupyter notebook outlines steps to fine-tune an OpenAI model for this purpose, utilising pharmaceutical/manufacturer data from the Electronic Medicines Compendium\n",
        "\n",
        "\n",
        "# **Things to fix:**\n",
        "\n",
        "1. Data extraction methods - checking for medicines that do not have spcs, only PILs\n",
        "2. Retraining model on missing medicines (consider concatenating data for single training cycle? 3 epochs might be better?)\n",
        "3. Formatting of data\n",
        "4. Validation/Testing sets\n",
        "5. Prompt variation adjustments for increased flexibility\n",
        "\n",
        "# UPDATE: No longer using OpenAI fine-tuning but RAG instead with Langchain"
      ],
      "metadata": {
        "id": "Z631m5Q8bZ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai -q\n",
        "!pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken\n",
        "!pip install beautifulsoup4 -q\n",
        "!pip install chromadb -q\n",
        "!pip install unstructured -q\n",
        "!pip install selenium -q\n",
        "!pip install --upgrade numpy -q\n",
        "!pip install jq -q"
      ],
      "metadata": {
        "id": "dtIfzWf_oLaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_community.document_loaders import SeleniumURLLoader\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "\n",
        "\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "aXFOVqtKF8mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1: Retrive url links of all medicines starting with a particular letter from the electronic medicines compendium\n",
        "\n",
        "#Set letter of drug name to search for\n",
        "letter = None #@param\n",
        "\n",
        "letter_url = f'https://www.medicines.org.uk/emc/browse-medicines/{letter}'\n",
        "\n",
        "def get_elements_of_letter(url):\n",
        "  \"\"\"Gets the total number of drugs under the specific letter\n",
        "  Args:\n",
        "    url: url of the durgs of a specific letter\n",
        "  \"\"\"\n",
        "  r = requests.get(url)\n",
        "  letter_soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  total_elements = letter_soup.find(class_='latest-updates-results-header-summary-total')\n",
        "  total_elements = total_elements.text.replace(\" \", \"\")\n",
        "  total_elements = int(total_elements.replace(\"resultsfound\", \"\"))\n",
        "  return total_elements\n",
        "\n",
        "def get_urls(num, link, show_progress=False,):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      num (int): number of items on the page\n",
        "      show_progress: prints the item being processed to the screen, default value is False\n",
        "\n",
        "  Returns:\n",
        "      A set with the links for each item\n",
        "  \"\"\"\n",
        "  output_urls = set()\n",
        "  for i in tqdm(range(1, num + 1, 50)):\n",
        "\n",
        "    #iterate over over site number\n",
        "    url_to_check = f'{link}?offset={i}&limit=50'\n",
        "    response = requests.get(url_to_check)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    url_title_links = soup.find_all(class_=\"search-results-product-info-title-link emc-link\")\n",
        "    for j in url_title_links:\n",
        "      if \"ablet\" in j.text:\n",
        "        if show_progress:\n",
        "          print(f\"Processing: {j.text}\")\n",
        "        href = 'https://www.medicines.org.uk/' + j.get('href')\n",
        "        output_urls.add(href)\n",
        "      if \"apsule\" in j.text:\n",
        "        if show_progress:\n",
        "          print(f\"Processing: {j.text}\")\n",
        "        href_cap = 'https://www.medicines.org.uk/' + j.get('href')\n",
        "        output_urls.add(href_cap)\n",
        "\n",
        "  return output_urls\n",
        "\n",
        "\n",
        "urls_to_check = get_urls(num=get_elements_of_letter(letter_url), link=letter_url)\n",
        "def append_to_file(filename, content):\n",
        "  with open(filename, \"a+\") as file:\n",
        "    # Check if file is empty (has no data)\n",
        "    if file.tell() == 0:\n",
        "      file.write(\"\")  # Add an empty line if the file is empty\n",
        "    else:\n",
        "      file.write(\"\\n\")  # Add a newline if there's existing content\n",
        "    file.write(content)\n",
        "\n",
        "for url in urls_to_check:\n",
        "  append_to_file(\"url_file.txt\", url)"
      ],
      "metadata": {
        "id": "f34xz9YH0mA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5c8891-5855-4ed9-f199-206771829117",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17/17 [00:19<00:00,  1.13s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: Screen through each drug link starting with a particular letter to obtain drug description and manufacturer details\n",
        "\n",
        "#Output anomalous spcs to an error file for subsequent review\n",
        "# nesting scraper in a single function for pharmaceutical form\n",
        "\n",
        "def find_drug_description(url):\n",
        "  r = requests.get(url)\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  # getting name of medicines\n",
        "  title_tag = soup.find(id='PRODUCTINFO')\n",
        "  try:\n",
        "    title_parent = title_tag.parent\n",
        "    title = title_parent.find(class_='sectionWrapper').text\n",
        "  except Exception as e:\n",
        "    title = \"\"\n",
        "    print(f\"DISCONTINUED/NO SPC: {url}\")\n",
        "    return url\n",
        "\n",
        "  # getting description of medicine\n",
        "  tag = soup.find(id='FORM')\n",
        "  try:\n",
        "    desc_parent = tag.parent\n",
        "    all_desc = desc_parent.find_all(recursive=False)  # Restrict search within the parent div\n",
        "    dsc_output = \"\"\n",
        "    for desc in all_desc:\n",
        "        if desc != tag:\n",
        "          # Exclude the target element itself # Process the sibling element\n",
        "          dsc_output = desc.text\n",
        "  except Exception as e:\n",
        "    dsc_output = \"\"\n",
        "    pass\n",
        "\n",
        "  # getting company name\n",
        "  try:\n",
        "    comp_name = soup.find(class_=\"product-header-company-name\").text\n",
        "  except Exception:\n",
        "    comp_name = \"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "  return title.replace(\"\\n\", \"\").replace(\"\\r\", \"\"), dsc_output.replace(\"\\n\", \"\"), comp_name.replace(\"\\n\", \"\")\n",
        "\n",
        "output_dict = []\n",
        "for i in tqdm(urls_to_check):\n",
        "  try:\n",
        "\n",
        "    if len(find_drug_description(i)) == 3:\n",
        "\n",
        "      name, description, company = find_drug_description(i)\n",
        "      output_dict.append({\"Name\": name,\n",
        "                  \"Description\": description,\n",
        "                  \"Company\": company})\n",
        "    else:\n",
        "      with open(f'error_spcs{letter}.txt', 'w') as f:\n",
        "        f.write(f'{find_drug_description(i)}' + '\\n')\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    continue\n",
        "\n",
        "df = pd.DataFrame(output_dict)\n",
        "print(df.to_string())\n",
        "df.to_csv(f'OSD({letter}).csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "C0mu649ar-fK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2b: Read through spc errors and re-get pill data\n",
        "with open(f'error_spcs{letter}.txt', 'r') as errorFile:\n",
        "  for line in errorFile:\n",
        "    try:\n",
        "      if len(find_drug_description(line)) == 3:\n",
        "\n",
        "        name, description, company = find_drug_description(line)\n",
        "        output_dict.append({\"Name\": name,\n",
        "                    \"Description\": description,\n",
        "                    \"Company\": company})\n",
        "      else:\n",
        "        with open(f'error_spcs{letter}.txt', 'w') as f:\n",
        "          f.write(f'{find_drug_description(i)}' + '\\n')\n",
        "    except Exception as e:\n",
        "      print(str(e))\n",
        "      continue"
      ],
      "metadata": {
        "id": "EmooLhjeKAX1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Convert the collected data to JSON format\n",
        "\n",
        "def direct_json(l):\n",
        "  training_data = []\n",
        "  for i in l:\n",
        "    merged_completion = i[\"Name\"] + \" \"+ i[\"Company\"].strip()\n",
        "    prompt_description = r\"\" + i[\"Description\"]\n",
        "    data_dict = {\"prompt\": prompt_description.replace('\\\\', ''), \"completion\": merged_completion}\n",
        "    training_data.append(data_dict)\n",
        "\n",
        "  return training_data\n",
        "\n",
        "training_data = direct_json(output_dict)\n",
        "print(json.dumps(training_data, indent=2, ensure_ascii=False))\n",
        "\n",
        "with open('loader_data.json', 'w') as a:\n",
        "  json.dump(training_data, a)\n"
      ],
      "metadata": {
        "id": "uSbewR9fi2yw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Filter through data to prepare training dataset\n",
        "\n",
        "#@markdown Rename training_file_name to unique jsonl file\n",
        "\n",
        "training_file_name = f\"training_data{letter}.jsonl\" #@param\n",
        "\n",
        "def prepare_data(dictionary_data, final_file_name):\n",
        "  with open(final_file_name, 'w') as outfile:\n",
        "\n",
        "    for entry in dictionary_data:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')\n",
        "\n",
        "def remove_nan_dicts(data):\n",
        "  \"\"\"\n",
        "  Removes dictionaries containing \"nan\" values from a JSON object or list.\n",
        "\n",
        "  Args:\n",
        "      data (object): The JSON data to process (dict or list).\n",
        "\n",
        "  Returns:\n",
        "      object: The modified JSON data with \"nan\" dictionaries removed.\n",
        "  \"\"\"\n",
        "  # Iterate through the list of dictionaries\n",
        "  output_json = []\n",
        "  for d in data:\n",
        "    if 'nan' in d.values():\n",
        "      continue\n",
        "    d.values().replace('\\r', '')\n",
        "    d.values().replace('\\t', '')\n",
        "    output_json.append(d)\n",
        "\n",
        "  return output_json\n",
        "\n",
        "\n",
        "nanless_data = remove_nan_dicts(training_data)\n",
        "prepare_data(nanless_data, training_file_name)\n",
        "print(json.dumps(nanless_data, indent=2))\n",
        "print(nanless_data)\n"
      ],
      "metadata": {
        "id": "o8yGQZfGqvUF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Upload data to OpenAI API fine-tuning\n",
        "\n",
        "#@markdown Obtain your own api key from OpenAI\n",
        "api_key = None #@param\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "training_file_id = client.files.create(\n",
        "  file=open(training_file_name, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "1t2TrY_fsX_o",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 6: Initiate model fine-tuning\n",
        "\n",
        "base_model = None #@param\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file=training_file_id.id,\n",
        "  model=base_model,\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 3,\n",
        "\t\"batch_size\": 3,\n",
        "\t\"learning_rate_multiplier\": 0.3\n",
        "  }\n",
        ")\n",
        "job_id = response.id\n",
        "status = response.status\n",
        "\n",
        "print(f'Fine-tunning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {response}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "id": "AxTbIhA4UlSq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 7: Use fine-tuned model using prompts to describe tablet or capsule details\n",
        "OPENAI_API_KEY=None #@param\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "result = client.fine_tuning.jobs.list()\n",
        "fine_tuned_model = result.data[0].fine_tuned_model\n",
        "for i in range(10):\n",
        "  new_prompt = \"I have a clear colourless/pale yellow coloured translucent oval shaped capsule. What is this drug?\"\n",
        "  answer = client.completions.create(\n",
        "    model=None #@param\n",
        "    prompt=new_prompt,\n",
        "    max_tokens=20\n",
        "  )\n",
        "\n",
        "\n",
        "  print(answer.choices[0].text)\n"
      ],
      "metadata": {
        "id": "VE1h7hjooKcu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NEW: Retrieval-Augmented Generation with LangChain**\n",
        "\n",
        "Work in Progress...."
      ],
      "metadata": {
        "id": "xpd2gAkqxHPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=None #@param\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are world class specialist in pharmaceutical products.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "chain = prompt | llm | output_parser"
      ],
      "metadata": {
        "id": "31JURtQExFtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "file_path='./loader_data.json'\n",
        "JSONdata = json.loads(Path(file_path).read_text())\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path=file_path,\n",
        "    jq_schema='.',\n",
        "    text_content=False)\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever(k=len(urls_to_check))\n",
        "\n",
        "# docs = retriever.invoke(\"I have a tablet with the following characteristics: White or almost white, flat, bevelled edges, barrel-shaped tablet debossed with 'C' on one side and '58' on the other side. The size is 8 mm x 6 mm. Could you tell me what this pill is, its manufacturer, and where you got that information from?\")\n",
        "# docs"
      ],
      "metadata": {
        "id": "aTubBCRU0kVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "question_to_ask = '''I have a tablet with the following characteristics:\n",
        "White to off-white round, flat tablets, with bevelled edges, embossed with '10' on one side and plain on the other.\n",
        "Could you suggest 5 drugs that it could be and the manufacturer?\n",
        "Give a confidence score with each answer'''\n",
        "\n",
        "\n",
        "chain.invoke(question_to_ask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qQ6q4uSjJvNr",
        "outputId": "74f8823e-8a42-444f-e5c5-f4a316b02c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Amlodipine 10 mg Tablets - FDC International Ltd (Confidence score: 100%)\\n2. Amlodipine 10 mg tablets - Mylan (Confidence score: 90%)\\n3. Amlodipine 10 mg Tablets - Ipca Laboratories UK Ltd (Confidence score: 80%)\\n4. Amlodipine 10 mg tablets - Zentiva (Confidence score: 70%)\\n5. Amlodipine 10 mg Tablets - Aurobindo Pharma - Milpharm Ltd (Confidence score: 60%)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}
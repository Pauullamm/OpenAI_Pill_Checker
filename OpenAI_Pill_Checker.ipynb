{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYJukGYtEXlmVtJbIu7GWq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description: Python scripts to prepare a text-based AI model fine-tuned on an OpenAI davinci-002 model\n",
        "\n",
        "Have you ever wanted a pill identifer tool to check the name of a tablet/capsule by its description?\n",
        "\n",
        "This Jupyter notebook outlines steps to fine-tune an OpenAI model for this purpose, utilising pharmaceutical/manufacturer data from the Electronic Medicines Compendium\n",
        "\n",
        "\n",
        "# **Things to fix:**\n",
        "\n",
        "1. Data extraction methods - checking for medicines that do not have spcs, only PILs\n",
        "2. Retraining model on missing medicines (consider concatenating data for single training cycle? 3 epochs might be better?)\n",
        "3. Formatting of data\n",
        "4. Validation/Testing sets\n",
        "5. Prompt variation adjustments for increased flexibility\n",
        "\n",
        "# UPDATE: No longer using OpenAI fine-tuning but RAG instead with Langchain"
      ],
      "metadata": {
        "id": "Z631m5Q8bZ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DEPENDENCIES\n",
        "!pip install --upgrade openai -q\n",
        "!pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken\n",
        "!pip install beautifulsoup4 -q\n",
        "!pip install chromadb -q\n",
        "!pip install unstructured -q\n",
        "!pip install selenium -q\n",
        "!pip install --upgrade numpy -q\n",
        "!pip install jq -q"
      ],
      "metadata": {
        "id": "dtIfzWf_oLaF",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title IMPORTS\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_community.document_loaders import SeleniumURLLoader\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "\n",
        "\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "aXFOVqtKF8mE",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./loader_data.json', mode='w', encoding='utf-8') as f:\n",
        "    json.dump([], f)"
      ],
      "metadata": {
        "id": "-9OsHd9iz70k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1: Retrive url links of all medicines starting with a particular letter from the electronic medicines compendium\n",
        "\n",
        "#Set letter of drug name to search for\n",
        "letter = \"C\" #@param\n",
        "\n",
        "letter_url = f'https://www.medicines.org.uk/emc/browse-medicines/{letter}'\n",
        "\n",
        "def get_elements_of_letter(url):\n",
        "  \"\"\"Gets the total number of drugs under the specific letter\n",
        "  Args:\n",
        "    url: url of the durgs of a specific letter\n",
        "  \"\"\"\n",
        "  r = requests.get(url)\n",
        "  letter_soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  total_elements = letter_soup.find(class_='latest-updates-results-header-summary-total')\n",
        "  total_elements = total_elements.text.replace(\" \", \"\")\n",
        "  total_elements = int(total_elements.replace(\"resultsfound\", \"\"))\n",
        "  return total_elements\n",
        "\n",
        "def get_urls(num, link, show_progress=False,):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      num (int): number of items on the page\n",
        "      show_progress: prints the item being processed to the screen, default value is False\n",
        "\n",
        "  Returns:\n",
        "      A set with the links for each item\n",
        "  \"\"\"\n",
        "  output_urls = set()\n",
        "  for i in tqdm(range(1, num + 1, 50)):\n",
        "\n",
        "    #iterate over over site number\n",
        "    url_to_check = f'{link}?offset={i}&limit=50'\n",
        "    response = requests.get(url_to_check)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    url_title_links = soup.find_all(class_=\"search-results-product-info-title-link emc-link\")\n",
        "    for j in url_title_links:\n",
        "      if \"ablet\" in j.text:\n",
        "        if show_progress:\n",
        "          print(f\"Processing: {j.text}\")\n",
        "        href = 'https://www.medicines.org.uk/' + j.get('href')\n",
        "        output_urls.add(href)\n",
        "      if \"apsule\" in j.text:\n",
        "        if show_progress:\n",
        "          print(f\"Processing: {j.text}\")\n",
        "        href_cap = 'https://www.medicines.org.uk/' + j.get('href')\n",
        "        output_urls.add(href_cap)\n",
        "\n",
        "  return output_urls\n",
        "\n",
        "\n",
        "urls_to_check = get_urls(num=get_elements_of_letter(letter_url), link=letter_url)\n",
        "def append_to_file(filename, content):\n",
        "  with open(filename, \"a+\") as file:\n",
        "    # Check if file is empty (has no data)\n",
        "    if file.tell() == 0:\n",
        "      file.write(\"\")  # Add an empty line if the file is empty\n",
        "    else:\n",
        "      file.write(\"\\n\")  # Add a newline if there's existing content\n",
        "    file.write(content)\n",
        "\n",
        "for url in urls_to_check:\n",
        "  append_to_file(\"url_file.txt\", url)"
      ],
      "metadata": {
        "id": "f34xz9YH0mA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85ab4d7-226b-4074-c6ba-1304c91dc89e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17/17 [00:07<00:00,  2.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: Screen through each drug link starting with a particular letter to obtain drug description and manufacturer details\n",
        "\n",
        "#Output anomalous spcs to an error file for subsequent review\n",
        "# nesting scraper in a single function for pharmaceutical form\n",
        "\n",
        "def find_drug_description(url):\n",
        "  r = requests.get(url)\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  # getting name of medicines\n",
        "  title_tag = soup.find(id='PRODUCTINFO')\n",
        "  try:\n",
        "    title_parent = title_tag.parent\n",
        "    title = title_parent.find(class_='sectionWrapper').text\n",
        "  except Exception as e:\n",
        "    title = \"\"\n",
        "    print(f\"DISCONTINUED/NO SPC: {url}\")\n",
        "    return url\n",
        "\n",
        "  # getting description of medicine\n",
        "  tag = soup.find(id='FORM')\n",
        "  try:\n",
        "    desc_parent = tag.parent\n",
        "    all_desc = desc_parent.find_all(recursive=False)  # Restrict search within the parent div\n",
        "    dsc_output = \"\"\n",
        "    for desc in all_desc:\n",
        "        if desc != tag:\n",
        "          # Exclude the target element itself # Process the sibling element\n",
        "          dsc_output = desc.text\n",
        "  except Exception as e:\n",
        "    dsc_output = \"\"\n",
        "    pass\n",
        "\n",
        "  # getting company name\n",
        "  try:\n",
        "    comp_name = soup.find(class_=\"product-header-company-name\").text\n",
        "  except Exception:\n",
        "    comp_name = \"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "  return title.replace(\"\\n\", \"\").replace(\"\\r\", \"\"), dsc_output.replace(\"\\n\", \"\"), comp_name.replace(\"\\n\", \"\")\n",
        "\n",
        "output_dict = []\n",
        "for i in tqdm(urls_to_check):\n",
        "  try:\n",
        "\n",
        "    if len(find_drug_description(i)) == 3:\n",
        "\n",
        "      name, description, company = find_drug_description(i)\n",
        "      output_dict.append({\"Name\": name,\n",
        "                  \"Description\": description,\n",
        "                  \"Company\": company})\n",
        "    else:\n",
        "      with open(f'error_spcs{letter}.txt', 'w') as f:\n",
        "        f.write('\\n' + f'{find_drug_description(i)}' + '\\n')\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    continue\n",
        "\n",
        "df = pd.DataFrame(output_dict)\n",
        "print(df.to_string())\n",
        "df.to_csv(f'OSD({letter}).csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "C0mu649ar-fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2b: Read through spc errors and re-get pill data\n",
        "with open(f'error_spcs{letter}.txt', 'r') as errorFile:\n",
        "  for line in errorFile:\n",
        "    try:\n",
        "      if len(find_drug_description(line)) == 3:\n",
        "\n",
        "        name, description, company = find_drug_description(line)\n",
        "        output_dict.append({\"Name\": name,\n",
        "                    \"Description\": description,\n",
        "                    \"Company\": company})\n",
        "      else:\n",
        "        with open(f'error_spcs{letter}.txt', 'w') as f:\n",
        "          f.write(f'{find_drug_description(i)}' + '\\n')\n",
        "    except Exception as e:\n",
        "      print(str(e))\n",
        "      continue"
      ],
      "metadata": {
        "id": "EmooLhjeKAX1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Convert the collected data to JSON format\n",
        "\n",
        "def direct_json(l):\n",
        "  training_data = []\n",
        "  for i in l:\n",
        "    merged_completion = i[\"Name\"] + \" \"+ i[\"Company\"].strip()\n",
        "    prompt_description = r\"\" + i[\"Description\"]\n",
        "    # data_dict = {\"prompt\": prompt_description.replace('\\\\', ''), \"completion\": merged_completion}\n",
        "    data_dict = {merged_completion : prompt_description.replace('\\\\', '')} # Testing with only json, removed \"prompt\" and \"completion\"\n",
        "\n",
        "    training_data.append(data_dict)\n",
        "\n",
        "  return training_data\n",
        "\n",
        "\n",
        "def append_to_json(filename, new_dict):\n",
        "  \"\"\"\n",
        "  Appends a dictionary to a list in a JSON file.\n",
        "\n",
        "  Args:\n",
        "    filename: The path to the JSON file.\n",
        "    new_dict: The dictionary to append to the list.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Open the file in read mode with 'r'\n",
        "    with open(filename, \"r\") as f:\n",
        "      # Try to load the data\n",
        "      try:\n",
        "        data = json.load(f)\n",
        "      except json.JSONDecodeError:\n",
        "        # Empty JSON file, create an empty list\n",
        "        data = []\n",
        "  except FileNotFoundError:\n",
        "    # File doesn't exist, create an empty list\n",
        "    data = []\n",
        "\n",
        "  # Ensure data is a list\n",
        "  if not isinstance(data, list):\n",
        "    raise ValueError(\"JSON data must be a list\")\n",
        "\n",
        "  # Append the new dictionary\n",
        "  data.append(new_dict)\n",
        "\n",
        "  # Open the file in write mode with 'w' to overwrite the content\n",
        "  with open(filename, \"w\") as f:\n",
        "    # Dump the updated data with indentation for readability\n",
        "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "filename='loader_data.json'\n",
        "training_data = direct_json(output_dict)\n",
        "\n",
        "for entry in tqdm(training_data):\n",
        "  append_to_json(filename, entry)\n",
        "\n",
        "print(training_data[:5])"
      ],
      "metadata": {
        "id": "uSbewR9fi2yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f5957d-787b-4719-9f2c-cad961053fb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56/56 [00:00<00:00, 367.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{' Bumetanide/Amiloride 1mg/5mg Tablets  Chemidex  Pharma  Ltd': \" Tablet. Cream coloured, flat, oval with bevelled edge tablets, scored on one side and engraved with '149' on the reverse. The score line is not intended for breaking the tablet. \"}, {' Bylvay 600 micrograms hard capsules  Albireo Pharma': ' Hard capsule  Size 0 capsule (21.7 mm × 7.64 mm) with ivory opaque cap and body; imprinted “ A600” with black ink. '}, {' Travel Calm Tablets  THE BOOTS COMPANY PLC': ' Tablets. '}, {' Buspirone Hydrochloride 5 mg Tablets   Mylan': ' Tablet. Buspirone Hydrochloride 5 mg Tablets are white, round, bevelled edge tablets, embossed “ BR 5” on one side, “ G” on the reverse. '}, {' Busulfan 2 mg tablets  Aspen': ' Film coated tablet Busulfan 2 mg tablets are white, film-coated, round biconvex tablets engraved “ GX EF3” on one side and “ M” on the other. '}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 4: Filter through data to prepare training dataset\n",
        "\n",
        "#@markdown Rename training_file_name to unique jsonl file\n",
        "\n",
        "training_file_name = f\"training_data{letter}.jsonl\" #@param\n",
        "\n",
        "def prepare_data(dictionary_data, final_file_name):\n",
        "  with open(final_file_name, 'w') as outfile:\n",
        "\n",
        "    for entry in dictionary_data:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')\n",
        "\n",
        "def remove_nan_dicts(data):\n",
        "  \"\"\"\n",
        "  Removes dictionaries containing \"nan\" values from a JSON object or list.\n",
        "\n",
        "  Args:\n",
        "      data (object): The JSON data to process (dict or list).\n",
        "\n",
        "  Returns:\n",
        "      object: The modified JSON data with \"nan\" dictionaries removed.\n",
        "  \"\"\"\n",
        "  # Iterate through the list of dictionaries\n",
        "  output_json = []\n",
        "  for d in data:\n",
        "    if 'nan' in d.values():\n",
        "      continue\n",
        "    d.values().replace('\\r', '')\n",
        "    d.values().replace('\\t', '')\n",
        "    output_json.append(d)\n",
        "\n",
        "  return output_json\n",
        "\n",
        "\n",
        "nanless_data = remove_nan_dicts(training_data)\n",
        "prepare_data(nanless_data, training_file_name)\n",
        "print(json.dumps(nanless_data, indent=2))\n",
        "print(nanless_data)\n"
      ],
      "metadata": {
        "id": "o8yGQZfGqvUF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Upload data to OpenAI API fine-tuning\n",
        "\n",
        "#@markdown Obtain your own api key from OpenAI\n",
        "api_key = None #@param\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "training_file_id = client.files.create(\n",
        "  file=open(training_file_name, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "1t2TrY_fsX_o",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 6: Initiate model fine-tuning\n",
        "\n",
        "base_model = None #@param\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file=training_file_id.id,\n",
        "  model=base_model,\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 3,\n",
        "\t\"batch_size\": 3,\n",
        "\t\"learning_rate_multiplier\": 0.3\n",
        "  }\n",
        ")\n",
        "job_id = response.id\n",
        "status = response.status\n",
        "\n",
        "print(f'Fine-tunning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {response}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "id": "AxTbIhA4UlSq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 7: Use fine-tuned model using prompts to describe tablet or capsule details\n",
        "OPENAI_API_KEY=None #@param\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "result = client.fine_tuning.jobs.list()\n",
        "fine_tuned_model = result.data[0].fine_tuned_model\n",
        "for i in range(10):\n",
        "  new_prompt = \"I have a clear colourless/pale yellow coloured translucent oval shaped capsule. What is this drug?\"\n",
        "  answer = client.completions.create(\n",
        "    model=None #@param\n",
        "    prompt=new_prompt,\n",
        "    max_tokens=20\n",
        "  )\n",
        "\n",
        "\n",
        "  print(answer.choices[0].text)\n"
      ],
      "metadata": {
        "id": "VE1h7hjooKcu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NEW: Retrieval-Augmented Generation with LangChain**\n",
        "\n",
        "Work in Progress...."
      ],
      "metadata": {
        "id": "xpd2gAkqxHPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_text_splitters -q\n",
        "from langchain_text_splitters import RecursiveJsonSplitter"
      ],
      "metadata": {
        "id": "e1b2DoR2oeXe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveJsonSplitter(max_chunk_size=300)\n",
        "# Recursively split json data - If you need to access/manipulate the smaller json chunks\n",
        "json_chunks = splitter.split_json(json_data=training_data, convert_lists=True)\n"
      ],
      "metadata": {
        "id": "ndf5GoWiptU6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=None #@param\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are world class specialist in pharmaceutical products.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "chain = prompt | llm | output_parser"
      ],
      "metadata": {
        "id": "31JURtQExFtn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "file_path='/content/loader_data.json'\n",
        "\n",
        "\n",
        "JSONdata = json.loads(Path(file_path).read_text())\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path=file_path,\n",
        "    jq_schema='.',\n",
        "    text_content=False)\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)\n"
      ],
      "metadata": {
        "id": "aTubBCRU0kVd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json_len(fileName):\n",
        "\n",
        "  try:\n",
        "    with open(fileName, \"r\") as f:\n",
        "      data_len = len(json.load(f))\n",
        "      return data_len\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: File '{filename}' not found.\")\n",
        "    return None\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Error: Invalid JSON data in '{filename}'.\")\n",
        "    return None\n",
        "\n",
        "retriever = vectorstore.as_retriever(k=get_json_len(file_path))\n",
        "docs = retriever.invoke(\"Opaque white and light brown hard gelatin capsule containing white to off- white powder (length: 14.5 mm).\")\n",
        "docs"
      ],
      "metadata": {
        "id": "QqgPkClGHGzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "question_to_ask = '''I have a pill with the following characteristics:\n",
        "Opaque white and light brown hard gelatin capsule containing white to off- white powder  (length: 14.5 mm).\n",
        "Could you tell me what this pill could be?\n",
        "'''\n",
        "\n",
        "\n",
        "chain.invoke(question_to_ask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qQ6q4uSjJvNr",
        "outputId": "b9199432-db5f-4883-aa60-24b709f57a6b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the characteristics described, the pill could be Adoport 1 mg Capsules by Sandoz Limited.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}